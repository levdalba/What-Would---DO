#!/usr/bin/env python3
"""
Quick test of the full parallel training pipeline
"""

import sys
from pathlib import Path

# Add the project directory to path
sys.path.append(str(Path(__file__).parent))

from stockfish_magnus_trainer import StockfishConfig, StockfishMagnusTrainer


def test_parallel_pipeline():
    """Test the complete parallel processing pipeline"""

    print("üß™ Testing complete parallel training pipeline...")
    print("=" * 60)

    # Quick test configuration
    config = StockfishConfig(
        pgn_file="../carlsen-games-quarter.pgn",
        max_games=5,  # Very small subset for quick test
        max_positions_per_game=10,
        num_epochs=2,  # Quick training
        batch_size=32,
        analysis_time=0.2,  # Fast analysis
        analysis_depth=12,
        use_parallel_analysis=True,
        max_threads=8,
        device="mps",
    )

    print(
        f"Configuration: {config.max_games} games, {config.max_threads} threads, {config.num_epochs} epochs"
    )

    trainer = StockfishMagnusTrainer(config)

    try:
        # Test dataset creation with parallel processing
        print("üìä Creating datasets with parallel processing...")
        train_loader, val_loader, test_loader = trainer.create_datasets()

        print(f"‚úÖ Dataset creation successful!")
        print(f"   Train samples: {len(train_loader.dataset)}")
        print(f"   Val samples: {len(val_loader.dataset)}")
        print(f"   Test samples: {len(test_loader.dataset)}")
        print(f"   Move vocabulary size: {train_loader.dataset.vocab_size}")

        # Test model creation
        from stockfish_magnus_trainer import MagnusStyleModel
        import json

        info_path = Path(config.model_save_dir) / "dataset_info.json"
        with open(info_path, "r") as f:
            dataset_info = json.load(f)

        model = MagnusStyleModel(
            config, dataset_info["vocab_size"], dataset_info["feature_dim"]
        )

        param_count = sum(p.numel() for p in model.parameters())
        print(f"‚úÖ Model created with {param_count:,} parameters")

        print("\nüéØ Parallel processing pipeline test PASSED!")
        print("Ready for full-scale training with 5.6x speedup!")

    except Exception as e:
        print(f"‚ùå Pipeline test FAILED: {e}")
        raise

    finally:
        trainer.analyzer.close()


if __name__ == "__main__":
    test_parallel_pipeline()
